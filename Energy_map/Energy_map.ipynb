{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3d8800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from os import path\n",
    "import json\n",
    "import time\n",
    "import pyodbc\n",
    "import webbrowser\n",
    "import shutil\n",
    "import csv\n",
    "import pandas as pd\n",
    "import folium\n",
    "import datetime\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# ヒュベニの公式\n",
    "# https://butter-tiger.hatenablog.com/entry/2020/08/20/222650\n",
    "POLE_RADIUS = 6356752  # 極半径(短半径)\n",
    "EQUATOR_RADIUS = 6378137  # 赤道半径(長半径)\n",
    "E = 0.081819191042815790  # 離心率\n",
    "E2 = 0.006694380022900788  # 離心率の２乗"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3353ec",
   "metadata": {},
   "source": [
    "<font size = 6 color =red>ここからは必要な関数を定義する↓</font>  \n",
    "  \n",
    "<font size = 3>この部分はisobe_arinaga_map\\config.py</font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2141b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#データベース接続\n",
    "driver='{SQL Server}'\n",
    "server = '*******************'\n",
    "database = '*******************'\n",
    "uid = '*******************'\n",
    "pwd = '*******************'\n",
    "trusted_connection ='yes'\n",
    "\n",
    "AltitudeAllTableName = '[*******************].[dbo].[ALTITUDE_10M_MESH]'\n",
    "AltitudeTableName = '[*******************].[dbo].[ALTITUDE_10M_MESH_REGISTERED_FIXED]' #通勤ルート用に補正したテーブル？\n",
    "EfficiencyTableName = '[*******************].[dbo].[EFFICIENCY_MAP]'\n",
    "EfficiencyMaxTableName = '[*******************].[dbo].[EFFICIENCY_MAP_MAX]'\n",
    "Cars_Tablename = '[*******************].[dbo].[CARS]'\n",
    "Place_Tablename = '[*******************].[dbo].[PLACE]'\n",
    "\n",
    "minTorque = 76  #EfficiencyMaxTableNameテーブルのTorqueカラムの最小値\n",
    "maxTorque = 280 #EfficiencyMaxTableNameテーブルのTorqueカラムの最大値\n",
    "maxRev = 9990   #EfficiencyMaxTableNameテーブルのRevカラムの最大値\n",
    "\n",
    "def select_execute(con, sql):\n",
    "    cursor = con.cursor()\n",
    "    cursor.execute(sql)\n",
    "    rows = cursor.fetchall()\n",
    "    columnNames = [column[0] for column in cursor.description]\n",
    "    cursor.close()\n",
    "    return rows, columnNames\n",
    "\n",
    "#https://www.codegrepper.com/code-examples/python/pyodbc.row+to+dictionary  sql -> dict変換の参考に\n",
    "class CarModel():\n",
    "    def __init__(self, car_id):\n",
    "        connect= pyodbc.connect('DRIVER='+driver+';SERVER='+server+';UID='+uid+';PED='+pwd+';DATABASE='+database+';Trusted_Connection='+trusted_connection+';')\n",
    "\n",
    "        sql = (\n",
    "            'SELECT CAR_ID, \\\n",
    "            MODEL, \\\n",
    "            WEIGHT, \\\n",
    "            TIRE_RADIUS, \\\n",
    "            REDUCTION_RATIO, \\\n",
    "            CD_VALUE, \\\n",
    "            FRONTAL_PROJECTED_AREA \\\n",
    "            FROM ' + Cars_Tablename\n",
    "            + 'WHERE CAR_ID = ' + str(car_id)\n",
    "        )\n",
    "        self.rows, self.column_Names = select_execute(connect, sql)\n",
    "        connect.close()\n",
    "\n",
    "    def get_car_model(self):\n",
    "        \n",
    "        dict_carModel = {}\n",
    "        column_Names2 = ['CarID', 'Model', 'CarWeight', 'TireRadius', 'ReductionRatio', 'CdValue', 'FrontalProjectedArea']\n",
    "\n",
    "        if len(self.rows) == 0:\n",
    "            print('CarIDが違います')\n",
    "            sys.exit()\n",
    "        elif len(self.rows) == 1:\n",
    "            print(self.rows[0])\n",
    "            print(type(self.rows[0]))\n",
    "            dict_carModel.update( dict( zip( column_Names2 , self.rows[0] ) ) )\n",
    "            dict_carModel['Weight'] = dict_carModel['CarWeight'] + CarOtherWeight\n",
    "        else:\n",
    "            print('CarID重複エラー？？')\n",
    "        return dict_carModel\n",
    "\n",
    "def get_max_driving_force(weight):\n",
    "    return -0.15 * GravityResistanceCoefficient * weight\n",
    "\n",
    "\n",
    "\n",
    "def isInPlace(lat, long, place_ID):\n",
    "    connect= pyodbc.connect('DRIVER='+driver+';SERVER='+server+';UID='+uid+';PED='+pwd+';DATABASE='+database+';Trusted_Connection='+trusted_connection+';')\n",
    "    sql = (\n",
    "            'SELECT START_LATITUDE, \\\n",
    "            END_LATITUDE, \\\n",
    "            START_LONGITUDE, \\\n",
    "            END_LONGITUDE \\\n",
    "            FROM ' + Place_Tablename\n",
    "            + ' WHERE PLACE_ID = ' + str(place_ID)\n",
    "        )\n",
    "    rows, column_Names = select_execute(connect, sql)\n",
    "    dict_place = {}\n",
    "    if len(rows) == 0:\n",
    "        print('PlaceIDが違います')\n",
    "        sys.exit()\n",
    "    elif len(rows) == 1:\n",
    "        print(rows[0])\n",
    "        dict_place.update( dict( zip( column_Names , rows[0] ) ) )\n",
    "        if dict_place['START_LATITUDE'] < lat and lat < dict_place['END_LATITUDE'] and dict_place['START_LONGITUDE'] < long and long < dict_place['END_LONGITUDE']:\n",
    "            return 'true'\n",
    "    else:\n",
    "        print('CarID重複エラー？？')\n",
    "\n",
    "\n",
    "    connect.close()\n",
    "\n",
    "    return 'false'\n",
    "\n",
    "\n",
    "\n",
    "#環境データ\n",
    "myu = 0.015\n",
    "rho = 1.22\n",
    "GravityResistanceCoefficient = 9.80665\n",
    "windSpeed = 0.0\n",
    "\n",
    "#車両データ\n",
    "'''\n",
    "Weight = 1600\n",
    "FrontProjectedArea = 2.19\n",
    "CdValue = 0.28\n",
    "TireRadius = 0.3155\n",
    "ReductionRatio = 7.9377\n",
    "'''\n",
    "'''\n",
    "Weight = 1760\n",
    "FrontProjectedArea = 2.24\n",
    "CdValue = 0.28\n",
    "TireRadius = 0.3234\n",
    "ReductionRatio = 8.1938\n",
    "'''\n",
    "InverterEfficiency = 0.95\n",
    "MaxDrivingPower = -30\n",
    "#MaxDrivingForce = -0.15 * GravityResistanceCoefficient * Weight\n",
    "CarOtherWeight = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490ff394",
   "metadata": {},
   "source": [
    "<font size = 3>この部分はisobe_arinaga_map\\MathUtil.py</font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb31a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#座標の系列データを入力とし、高度の系列データを出力するプログラム\n",
    "def altDao(gpsRows):\n",
    "    connect= pyodbc.connect('DRIVER='+driver+';SERVER='+server+';UID='+uid+';PED='+pwd+';DATABASE='+database+';Trusted_Connection='+trusted_connection+';')\n",
    "    altitudeList = []\n",
    "    for i in gpsRows:\n",
    "        _lat = str(i[0])\n",
    "        _long = str(i[1])\n",
    "        sql = 'SELECT ALTITUDE FROM ' + AltitudeTableName + ' WHERE LOWER_LATITUDE <= ' + _lat + ' AND UPPER_LATITUDE > ' + _lat + ' AND LOWER_LONGITUDE <= ' + _long + ' AND UPPER_LONGITUDE > ' + _long\n",
    "        \n",
    "        rows = select_execute(connect, sql)\n",
    "        if len(rows) > 0:\n",
    "            altitude = round(float(str(rows[0]).replace(', )', '').replace('(', '')), 3)\n",
    "        else:   #FIXEDのテーブルになかった場合\n",
    "            sql = 'SELECT ALTITUDE FROM ' + AltitudeAllTableName + ' WHERE LOWER_LATITUDE <= ' + _lat + ' AND UPPER_LATITUDE > ' + _lat + ' AND LOWER_LONGITUDE <= ' + _long + ' AND UPPER_LONGITUDE > ' + _long\n",
    "            rows = select_execute(connect, sql)\n",
    "            if len(rows) > 0:\n",
    "                altitude = round(float(str(rows[0]).replace(', )', '').replace('(', '')), 3)\n",
    "            else:\n",
    "                altitude = -99\n",
    "                print(str(i) + '高度データを取得できませんでした')\n",
    "        #print(str(i) + ' -> ' + str(altitude))\n",
    "        altitudeList.append(altitude)\n",
    "    print('--- altitude insert finished ---\\n')\n",
    "    connect.close()\n",
    "    #print(altitudeList)\n",
    "    return altitudeList\n",
    "\n",
    "\n",
    "def Calc_Heading(_lat1, _long1, _lat2, _long2):\n",
    "    heading = 0\n",
    "    lat1 = _lat1 * math.pi / 180\n",
    "    long1 = _long1 * math.pi / 180\n",
    "    lat2 = _lat2 * math.pi / 180\n",
    "    long2 = _long2 * math.pi / 180\n",
    "\n",
    "    y = math.cos(lat2) * math.sin(long2 - long1)\n",
    "    x = math.cos(lat1) * math.sin(lat2) - math.sin(lat1) * math.cos(lat2) * math.cos(long2 - long1)\n",
    "    heading = math.atan2(y, x) * 180 / math.pi\n",
    "    if heading < 0:\n",
    "        heading = heading + 360\n",
    "\n",
    "    return heading\n",
    "\n",
    "def select_execute(con, sql):\n",
    "    cursor = con.cursor()\n",
    "    cursor.execute(sql)\n",
    "    rows = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    return rows\n",
    "\n",
    "def get_efficiency(speed, torque, dict_carModel):\n",
    "\n",
    "    #print('---最大効率の処理を入れる必要あり---')\n",
    "    efficiency = -1\n",
    "    rpm = speed * 60 / (dict_carModel['TIRE_RADIUS'].iloc[0] * 2 * math.pi) * dict_carModel['REDUCTION_RATIO'].iloc[0]\n",
    "    rev = math.floor(rpm / 10) * 10 #四捨五入ではなく切り捨て\n",
    "    #print('rev:', rev, '  torque:', torque)\n",
    "    connect= pyodbc.connect('DRIVER='+driver+';SERVER='+server+';UID='+uid+';PED='+pwd+';DATABASE='+database+';Trusted_Connection='+trusted_connection+';')\n",
    "\n",
    "    if rpm <= maxRev and torque <= maxTorque and torque >= minTorque:   #C#のSensorLogInserterはここの条件が逆になってる？？\n",
    "        sql = 'SELECT EFFICIENCY FROM ' + EfficiencyMaxTableName + ' WHERE torque = ' + str(torque) + ' AND REV = ' + str(rev)\n",
    "        rows = select_execute(connect, sql)\n",
    "        if len(rows) > 0:\n",
    "            efficiency = int(str(rows[0]).replace(', )', '').replace('(', ''))\n",
    "            #print(efficiency, '  MAX')\n",
    "    if efficiency == -1:\n",
    "#         print('rpm: ',rpm)\n",
    "#         print('rev: ',rev)\n",
    "        sql = 'SELECT EFFICIENCY FROM ' + EfficiencyTableName + ' WHERE torque = ' + str(torque) + ' AND REV = ' + str(rev)\n",
    "        rows = select_execute(connect, sql)\n",
    "        if len(rows) > 0:\n",
    "            efficiency = int(str(rows[0]).replace(', )', '').replace('(', ''))\n",
    "            #print(efficiency, '  not MAX')\n",
    "    if efficiency == -1:\n",
    "        print('rpm: ',rpm)\n",
    "        print('rev: ',rev)\n",
    "        efficiency = 75\n",
    "        print('変換効率取得で想定外の分岐が発生')\n",
    "    #print(efficiency)\n",
    "    connect.close()\n",
    "    return efficiency\n",
    "\n",
    "def Calc_RegeneEnergy(drivingPower, speed, efficiency, weight):\n",
    "    regeneEnergy = 0\n",
    "    if speed < 7 / 3.6:\n",
    "        drivingForce = 0\n",
    "    else:\n",
    "        drivingForce = drivingPower * 1000 * 3600 / speed   #制動力[N]\n",
    "    speedC = MaxDrivingPower * 1000 / get_max_driving_force(weight)   #限界回生力と限界回生エネルギーの時の回生力の低い方が変わるときの車速[m/s]\n",
    "    if drivingPower < 0:\n",
    "        if speed < 7 / 3.6:\n",
    "            regeneEnergy = 0\n",
    "        elif drivingPower * 3600 >= MaxDrivingPower and drivingForce >= get_max_driving_force(weight):\n",
    "            regeneEnergy = drivingPower * efficiency\n",
    "        elif speed <= speedC and drivingForce < get_max_driving_force(weight):\n",
    "            regeneEnergy = get_max_driving_force(weight) * speed * efficiency / 3600 / 1000\n",
    "        elif drivingPower * 3600 < MaxDrivingPower and speed > speedC:\n",
    "            regeneEnergy = MaxDrivingPower / 3600 * efficiency\n",
    "        else:\n",
    "            regeneEnergy = 0\n",
    "            print('回生制約で想定外の分岐が発生  speed:', str(speed), '  power:', str(drivingPower), '  efficiency:', str(efficiency))\n",
    "        regeneEnergy = regeneEnergy / 100 * InverterEfficiency\n",
    "        if(drivingPower > regeneEnergy):\n",
    "            print(\"ドライビングパワーよりも回生エネルギーの方が大きくなっている，至急確認せよ\")\n",
    "            print(drivingPower, '  ', speed, '  ', efficiency, '  ', weight)\n",
    "    return regeneEnergy\n",
    "\n",
    "#ヒュベニの公式\n",
    "#https://butter-tiger.hatenablog.com/entry/2020/08/20/222650\n",
    "POLE_RADIUS = 6356752    # 極半径(短半径)\n",
    "EQUATOR_RADIUS = 6378137 # 赤道半径(長半径)\n",
    "E = 0.081819191042815790 # 離心率\n",
    "E2= 0.006694380022900788 # 離心率の２乗\n",
    "def distance(_lat1, _long1, _lat2, _long2):\n",
    "    lat1 = math.radians(_lat1)\n",
    "    long1 = math.radians(_long1)\n",
    "    lat2 = math.radians(_lat2)\n",
    "    long2 = math.radians(_long2)\n",
    "    m_lat = (lat1 + lat2) / 2 # 平均緯度\n",
    "    d_lat = abs(lat1 - lat2) # 緯度差\n",
    "    d_lon = abs(long1 - long2) # 経度差\n",
    "    W = math.sqrt(1-E2*math.pow(math.sin(m_lat),2))\n",
    "    M = EQUATOR_RADIUS*(1-E2) / math.pow(W, 3) # 子午線曲率半径\n",
    "    N = EQUATOR_RADIUS / W # 卯酉線曲率半径\n",
    "    # d = math.sqrt(math.pow(M*d_lat,2) + math.pow(N*d_lon*math.cos(m_lat),2) + math.pow(point_a.altitude-point_b.altitude,2))\n",
    "    d = math.sqrt(math.pow(M*d_lat,2) + math.pow(N*d_lon*math.cos(m_lat),2))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b38511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_to_dict_UTF8(input_jsonpath):\n",
    "    fp = open(input_jsonpath, \"r\", encoding=\"utf-8_sig\")\n",
    "    json_load = json.load(fp)\n",
    "    return json_load\n",
    "\n",
    "def distance(_lat1, _long1, _lat2, _long2):\n",
    "    lat1 = math.radians(_lat1)\n",
    "    long1 = math.radians(_long1)\n",
    "    lat2 = math.radians(_lat2)\n",
    "    long2 = math.radians(_long2)\n",
    "    m_lat = (lat1 + lat2) / 2  # 平均緯度\n",
    "    d_lat = abs(lat1 - lat2)  # 緯度差\n",
    "    d_lon = abs(long1 - long2)  # 経度差\n",
    "    W = math.sqrt(1 - E2 * math.pow(math.sin(m_lat), 2))\n",
    "    M = EQUATOR_RADIUS * (1 - E2) / math.pow(W, 3)  # 子午線曲率半径\n",
    "    N = EQUATOR_RADIUS / W  # 卯酉線曲率半径\n",
    "    # d = math.sqrt(math.pow(M*d_lat,2) + math.pow(N*d_lon*math.cos(m_lat),2) + math.pow(point_a.altitude-point_b.altitude,2))\n",
    "    d = math.sqrt(math.pow(M * d_lat, 2) + math.pow(N * d_lon * math.cos(m_lat), 2))\n",
    "    return d\n",
    "\n",
    "\n",
    "# convert JSON to [Latitude, Longitude, *******************_Elevation]\n",
    "\n",
    "def ADASListGenerator_to_df(semantic_link_id,json_*******************_filepath):\n",
    "    json_semanticlinkID_name = semantic_link_id \n",
    "\n",
    "\n",
    "    data_json = pd.DataFrame({'SemanticLink':[],\n",
    "                              'Latitude':[],\n",
    "                              'Longitude':[],\n",
    "                              '*******************_Elevation':[],\n",
    "                              'adas_null':[]})\n",
    "\n",
    "    ## データ抽出\n",
    "    *******************_response_json_list = []\n",
    "    *******************_response_json_list = load_json_to_dict_UTF8(json_*******************_filepath)  # jsonの大外がリスト構造\n",
    "    global adas_null \n",
    "    \n",
    "\n",
    "    for i in range(len(load_json_to_dict_UTF8(json_*******************_filepath))):\n",
    "        for j in range(len(load_json_to_dict_UTF8(json_*******************_filepath)[i]['result']['path'])):\n",
    "            if 'adas' in load_json_to_dict_UTF8(json_*******************_filepath)[i]['result']['path'][j]['matchLink']:\n",
    "                adas_null = 0\n",
    "                if str(load_json_to_dict_UTF8(json_*******************_filepath)[i]['result']['path'][j]['matchLink']['adas']) == 'None':\n",
    "                    adas_null = 1\n",
    "                    continue\n",
    "                roadelevation = load_json_to_dict_UTF8(json_*******************_filepath)[i]['result']['path'][j]['matchLink']['adas']['roadelevation']\n",
    "                for h in range(len(roadelevation)):\n",
    "                    adasPoint = load_json_to_dict_UTF8(json_*******************_filepath)[i]['result']['path'][j]['matchLink']['adas']['roadelevation'][h]\n",
    "                    data_json.loc[len(data_json)+1] = [json_semanticlinkID_name, adasPoint[\"lat\"], adasPoint[\"lon\"], adasPoint[\"elevation\"], adas_null]\n",
    "\n",
    "    data_json.reset_index(drop = True,inplace = True)\n",
    "    return data_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3fa12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_SEGMENTS_ZDC(semantic_link_id ,segment_distance):\n",
    "    driver='{SQL Server}'\n",
    "    server = '*******************'\n",
    "    database = '*******************'\n",
    "    trusted_connection='yes'\n",
    "    table_SEGMENTS_ZDC = 'SEGMENTS_ZDC_' + str(segment_distance) + 'M'\n",
    "    table_SEMANTIC_LINKS_SEGMENTS = 'SEMANTIC_LINKS_SEGMENTS_' + str(segment_distance) + 'M'\n",
    "    connect= pyodbc.connect('DRIVER='+driver+';SERVER='+server+';DATABASE='+database+';PORT=1433;Trusted_Connection='+trusted_connection+';')\n",
    "    cursor = connect.cursor()\n",
    "    sql_query = \"select * from \" + table_SEGMENTS_ZDC+\",\"+table_SEMANTIC_LINKS_SEGMENTS + \" where \"+table_SEMANTIC_LINKS_SEGMENTS+\".SEGMENT_ID = \"+table_SEGMENTS_ZDC+\".SEGMENT_ID and SEMANTIC_LINK_ID = \"+str(semantic_link_id )\n",
    "    cursor.execute(sql_query) \n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    cursor.close()\n",
    "    connect.close()\n",
    "    return rows\n",
    "\n",
    "def get_Car_model_datas(car_id):\n",
    "    driver='{SQL Server}'\n",
    "    server = '*******************'\n",
    "    database = '*******************'\n",
    "    trusted_connection='yes'\n",
    "    connect= pyodbc.connect('DRIVER='+driver+';SERVER='+server+';DATABASE='+database+';PORT=1433;Trusted_Connection='+trusted_connection+';')\n",
    "    cursor = connect.cursor()\n",
    "    sql_query = \"select * from CARS where CAR_ID = \"+str(car_id)\n",
    "    cursor.execute(sql_query) \n",
    "    rows = cursor.fetchall()\n",
    "    while len(rows) < 1 :\n",
    "        print('CAR_id入力間違いです。確認の上、改めて入力してください:')\n",
    "        car_id = input()\n",
    "        sql_query = \"select * from CARS where CAR_ID = \"+ car_id\n",
    "        cursor.execute(sql_query)\n",
    "        rows = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    connect.close()\n",
    "    return rows\n",
    "\n",
    "def display_folium_map_from_csv(data,path):\n",
    "    output_folium_file_path = path\n",
    "    df_output_points = data.iloc[:,1:3]\n",
    "    folium_map = folium.Map(\n",
    "        location=[\n",
    "            df_output_points.at[len(df_output_points) // 2, \"LATITUDE\"],\n",
    "            df_output_points.at[len(df_output_points) // 2, \"LONGITUDE\"],\n",
    "        ],\n",
    "        zoom_start=13,\n",
    "    )\n",
    "    for index, point in df_output_points.iterrows():\n",
    "        folium.Marker(location=[point[\"LATITUDE\"], point[\"LONGITUDE\"]]).add_to(\n",
    "            folium_map\n",
    "        )\n",
    "    folium_map.save(output_folium_file_path)\n",
    "    #webbrowser.open(output_folium_file_path, new=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd545a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMLファイルの中から，必要な座標列のみを抽出し，リスト形式で返すメソッド\n",
    "def readLinksKML(filename):\n",
    "    lineSirungTab1 = r\"<LineString>\"\n",
    "    lineSirungTab2 = r\"</LineString>\"\n",
    "    isLineString = 0\n",
    "    f = open(filename, \"r\", encoding=\"UTF-8\")\n",
    "    datalist = f.readlines()\n",
    "    GPSlist = [[\"Latitude\", \"Longitude\"]]\n",
    "    for data in datalist:\n",
    "        if isLineString == 1:\n",
    "            if lineSirungTab2 in data:\n",
    "                # print('ここまでが対象データ')\n",
    "                isLineString = 0\n",
    "            else:\n",
    "                target_data = data.replace(\" \", \"\").replace(r\",0\", \"\")\n",
    "                if re.match(r\"[0-9]+.?[0-9]*,[0-9]+.?[0-9]*\", target_data):\n",
    "                    target_data2 = re.split(\",\", target_data)\n",
    "                    appendList = [float(target_data2[1]), float(target_data2[0])]\n",
    "                    GPSlist.append(appendList)\n",
    "                    # print(appendList)\n",
    "        elif isLineString == 0:\n",
    "            if lineSirungTab1 in data:\n",
    "                # print('ここからが対象データ')\n",
    "                isLineString = 1\n",
    "        else:\n",
    "            print(\"よきせぬれーがい\")\n",
    "    GPSlist.remove([\"Latitude\", \"Longitude\"])\n",
    "    return GPSlist\n",
    "\n",
    "\n",
    "def calcDistance(list_GPS):\n",
    "    list_lat_long_dist = [\n",
    "        [\"Latitude1\", \"Longitude1\", \"Latitude2\", \"Longitude2\", \"Distance\"]\n",
    "    ]\n",
    "    before_lat = 0\n",
    "    before_long = 0\n",
    "    dist_sum = 0\n",
    "    for row in list_GPS:\n",
    "        if before_lat > 0:\n",
    "            dist = distance(before_lat, before_long, row[0], row[1])\n",
    "            appendList = [before_lat, before_long, row[0], row[1], dist]\n",
    "            list_lat_long_dist.append(appendList)\n",
    "            dist_sum = dist_sum + dist\n",
    "            # print(appendList)\n",
    "        before_lat = row[0]\n",
    "        before_long = row[1]\n",
    "    list_lat_long_dist.remove(\n",
    "        [\"Latitude1\", \"Longitude1\", \"Latitude2\", \"Longitude2\", \"Distance\"]\n",
    "    )\n",
    "    return list_lat_long_dist, dist_sum\n",
    "\n",
    "def normalizedCoordinatesGenerator(list_lat_long_dist, normalized_dist):\n",
    "    normalizedList = [[\"Latitude\", \"Longitude\"]]\n",
    "    rest = normalized_dist\n",
    "    _lat = list_lat_long_dist[0][0]\n",
    "    _long = list_lat_long_dist[0][1]\n",
    "    appendList = [_lat, _long]\n",
    "    normalizedList.append(appendList)\n",
    "    coordinatesNumber = 1\n",
    "\n",
    "    for row in list_lat_long_dist:\n",
    "        row_loop = 0\n",
    "        if rest > row[4]:\n",
    "            rest = rest - row[4]\n",
    "            # print('rest:', str(rest))\n",
    "        else:\n",
    "            while rest + normalized_dist * row_loop < row[4]:\n",
    "                _lat = (row[2] - row[0]) * (rest + normalized_dist * row_loop) / row[\n",
    "                    4\n",
    "                ] + row[0]\n",
    "                _long = (row[3] - row[1]) * (rest + normalized_dist * row_loop) / row[\n",
    "                    4\n",
    "                ] + row[1]\n",
    "                appendList = [_lat, _long]\n",
    "                normalizedList.append(appendList)\n",
    "                coordinatesNumber = coordinatesNumber + 1\n",
    "                row_loop = row_loop + 1\n",
    "                # print('rest:', str(rest))\n",
    "            rest = rest - row[4] + normalized_dist * row_loop\n",
    "    \n",
    "    return normalizedList, coordinatesNumber\n",
    "\n",
    "def GPSListGenerator_segment(filename,speed):\n",
    "    list_GPS = readLinksKML(filename)  # KMLファイルの中から，必要な座標列のみを抽出し，リスト形式で返す\n",
    "    # print(list_GPS)    #(lat, long)\n",
    "    list_lat_long_dist, dist_sum = calcDistance(list_GPS)\n",
    "    NORMALIZED_DISTANCE = speed\n",
    "\n",
    "    normalized_dist = NORMALIZED_DISTANCE\n",
    "\n",
    "    list_normalized_lat_long, coordinatesNumber = normalizedCoordinatesGenerator(\n",
    "        list_lat_long_dist, normalized_dist\n",
    "    )\n",
    "    \n",
    "    return list_normalized_lat_long\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8a62ce",
   "metadata": {},
   "source": [
    "<font size = 6 color =red> ここからは実行↓ </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c586ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--------------------------------')\n",
    "\n",
    "print('Semantic_link_idを指定してください(整数)')\n",
    "semantic_link_id = input()\n",
    "semantic_link_id = int(semantic_link_id)\n",
    "\n",
    "\n",
    "kml_filename =  Path(path.join(path.dirname(os.getcwd()), \".\" +\"\\Energy_map\\INPUT\\kml_Semantics\\{}.kml\".format(str(semantic_link_id))))\n",
    "json_*******************_filepath =  Path(path.join(path.dirname(os.getcwd()), \".\" +\"\\Energy_map\\INPUT\\*******************\\{}.json\".format(str(semantic_link_id))))\n",
    "csv_*******************_filepath =  Path(path.join(path.dirname(os.getcwd()), \".\" +\"\\Energy_map\\INPUT\\*******************\\{}.csv\".format(str(semantic_link_id))))\n",
    "\n",
    "\n",
    "print('ACC setting Speedを指定してください(km/h)（整数）：')\n",
    "Speed = input()\n",
    "Speed_for_output = int(Speed)\n",
    "Speed = int(Speed)*0.92 /3.6\n",
    "print('--------------------------------')\n",
    "print('Virtual constant velocity runing LOG生成中です,場合によって1min以上かかることがある')\n",
    "distance_between_segments = Speed\n",
    "segment_distance = Speed\n",
    "#read kml and convert it to a DataFrame\n",
    "#仮想走行ログの座標群を生成する\n",
    "df_Coordinate = pd.DataFrame(GPSListGenerator_segment(kml_filename,Speed)[1:],columns =GPSListGenerator_segment(kml_filename,Speed)[0])\n",
    "Coordinate_id_series = list(range(len(df_Coordinate)))\n",
    "\n",
    "df_Coordinate['Coordinate_id'] = Coordinate_id_series\n",
    "\n",
    "#To match link_id of roads, a Knn classifier is trained with datas extracted from the df_segment\n",
    "train_data = df_Coordinate.iloc[:,0:2]\n",
    "train_label = df_Coordinate.iloc[:,-1]\n",
    "Classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "Classifier.fit(train_data,train_label)\n",
    "#Use trained classifier to match roads\n",
    "#you can trust this classifier cause of I set n_neighbors to 1,and it must overfitting\n",
    "#so its accuracy will be 100%\n",
    "\n",
    "if semantic_link_id in [****************************************************]:\n",
    "    df_******************* = pd.read_csv(csv_*******************_filepath)\n",
    "    df_******************* = df_*******************.iloc[:,1:]\n",
    "else:\n",
    "    df_******************* = ADASListGenerator_to_df(semantic_link_id ,json_*******************_filepath)\n",
    "Classifier_result_for_******************* = Classifier.predict(df_*******************.iloc[:,1:3])\n",
    "#The following DataFrame was created to aggregate the training results and to organize the data\n",
    "Data_virtual_run = pd.DataFrame({'SEGMENT_ID':[],\n",
    "                                                'SEGMENT_LENGTH':[],\n",
    "                                                'START_LATITUDE':[],\n",
    "                                                'START_LONGITUDE':[],\n",
    "                                                'END_LATITUDE':[],\n",
    "                                                'END_LONGITUDE':[],\n",
    "                                                'START_ADAS_ELEVATION_MILLI_METER':[],\n",
    "                                                'END_ADAS_ELEVATION_MILLI_METER':[],\n",
    "                                                'SLOPE_ANGLE_THETA':[],\n",
    "                                                'COS_THETA':[],\n",
    "                                                'SIN_THETA':[],\n",
    "                                                'IS_ADAS_NULL':[],\n",
    "                                                'IS_GET_ZDC_DATA':[]\n",
    "                                                })\n",
    "Data_virtual_run.SEGMENT_ID = df_Coordinate.Coordinate_id.iloc[0:-1]\n",
    "Data_virtual_run.START_LATITUDE = df_Coordinate.Latitude.iloc[0:-1]\n",
    "Data_virtual_run.START_LONGITUDE = df_Coordinate.Longitude.iloc[0:-1]\n",
    "Data_virtual_run.END_LATITUDE = df_Coordinate.Latitude.iloc[1:].reset_index(drop = True)\n",
    "Data_virtual_run.END_LONGITUDE = df_Coordinate.Longitude.iloc[1:].reset_index(drop = True)\n",
    "\n",
    "\n",
    "#insert Classified df_******************* to Data_virtual_run\n",
    "for i in range(len(Classifier_result_for_*******************)):\n",
    "    index = Data_virtual_run.SEGMENT_ID.isin([Classifier_result_for_*******************[i]])\n",
    "    Data_virtual_run.START_ADAS_ELEVATION_MILLI_METER.iloc[index] = df_*******************.*******************_Elevation.loc[i]\n",
    "    Data_virtual_run.IS_ADAS_NULL.iloc[index] = df_*******************.adas_null.loc[i]\n",
    "\n",
    "#ここからはClassifierできない部分に対して、加重平均などの手法で欠損を埋める\n",
    "index_after = 0\n",
    "index_before = 0\n",
    "index_NOT_nan_list = list(Data_virtual_run[~Data_virtual_run.START_ADAS_ELEVATION_MILLI_METER.isna()].index)\n",
    "index_nan_list = list(Data_virtual_run[Data_virtual_run.START_ADAS_ELEVATION_MILLI_METER.isna()].index)\n",
    "IS_GET_ZDC_DATA=[]\n",
    "for i in range(len(Data_virtual_run.START_ADAS_ELEVATION_MILLI_METER.isna())):\n",
    "    IS_GET_ZDC_DATA.append(int(~Data_virtual_run.START_ADAS_ELEVATION_MILLI_METER.isna()[i]))\n",
    "Data_virtual_run['IS_GET_ZDC_DATA'] = IS_GET_ZDC_DATA\n",
    "\n",
    "before = 0\n",
    "after = 0\n",
    "if str(Data_virtual_run.iloc[0]['START_ADAS_ELEVATION_MILLI_METER']) == 'nan':\n",
    "    Data_virtual_run['START_ADAS_ELEVATION_MILLI_METER'].iloc[0] = Data_virtual_run['START_ADAS_ELEVATION_MILLI_METER'].iloc[index_NOT_nan_list[0]]\n",
    "    \n",
    "if str(Data_virtual_run.iloc[-1]['START_ADAS_ELEVATION_MILLI_METER']) == 'nan':\n",
    "    Data_virtual_run['START_ADAS_ELEVATION_MILLI_METER'].iloc[-1] = Data_virtual_run['START_ADAS_ELEVATION_MILLI_METER'].iloc[index_NOT_nan_list[-1]]\n",
    "#ここからは加重平均\n",
    "while Data_virtual_run.START_ADAS_ELEVATION_MILLI_METER.isnull().sum() !=0:\n",
    "    for i in range(len(Data_virtual_run)-1):\n",
    "        if str(Data_virtual_run.iloc[i]['START_ADAS_ELEVATION_MILLI_METER'])== 'nan':\n",
    "            before = Data_virtual_run.iloc[i-1]['START_ADAS_ELEVATION_MILLI_METER']\n",
    "            index_before = i-1\n",
    "            #print('index_before:',index_before,' ','before:',before)\n",
    "            for j in range(i,len(Data_virtual_run)):\n",
    "                if str(Data_virtual_run.iloc[j]['START_ADAS_ELEVATION_MILLI_METER'])!= 'nan':\n",
    "                    after = Data_virtual_run.iloc[j]['START_ADAS_ELEVATION_MILLI_METER']\n",
    "                    index_after = j\n",
    "                    #print('index_after:',index_after,' ','after:',after)\n",
    "                    break\n",
    "            distance_before_to_after = distance(Data_virtual_run.iloc[index_before]['START_LATITUDE'], \n",
    "                                                Data_virtual_run.iloc[index_before]['START_LONGITUDE'],\n",
    "                                                Data_virtual_run.iloc[index_after]['START_LATITUDE'],\n",
    "                                                Data_virtual_run.iloc[index_after]['START_LONGITUDE'])\n",
    "\n",
    "            rate_before = distance(Data_virtual_run.iloc[index_before]['START_LATITUDE'], \n",
    "                                   Data_virtual_run.iloc[index_before]['START_LONGITUDE'],\n",
    "                                   Data_virtual_run.iloc[i]['START_LATITUDE'],\n",
    "                                   Data_virtual_run.iloc[i]['START_LONGITUDE'])/distance_before_to_after\n",
    "            rate_after = distance(Data_virtual_run.iloc[i]['START_LATITUDE'], \n",
    "                                  Data_virtual_run.iloc[i]['START_LONGITUDE'],\n",
    "                                  Data_virtual_run.iloc[index_after]['START_LATITUDE'],\n",
    "                                  Data_virtual_run.iloc[index_after]['START_LONGITUDE'])/distance_before_to_after\n",
    "            #print(before * (1-rate_before) + after*(1-rate_after))\n",
    "            Data_virtual_run['START_ADAS_ELEVATION_MILLI_METER'].iloc[i] = before * (1-rate_before) + after*(1-rate_after)\n",
    "            #print('for this loop:',Data_for_inserting.iloc[i]['START_ADAS_ELEVATION_MILLI_METER'])\n",
    "            break\n",
    "\n",
    "#次のstartは前のend\n",
    "Data_virtual_run['END_ADAS_ELEVATION_MILLI_METER'].iloc[1:] = Data_virtual_run['START_ADAS_ELEVATION_MILLI_METER'].iloc[0:-1]\n",
    "Data_virtual_run['END_ADAS_ELEVATION_MILLI_METER'].iloc[0] = Data_virtual_run['START_ADAS_ELEVATION_MILLI_METER'].iloc[0]\n",
    "#segment間隔を挿入\n",
    "Data_virtual_run['SEGMENT_LENGTH'] = Speed\n",
    "\n",
    "#startとendの標高差を利用して勾配を算出\n",
    "for i in range(len(Data_virtual_run)):\n",
    "    delta_ELEVATION = Data_virtual_run['END_ADAS_ELEVATION_MILLI_METER'].iloc[i] - Data_virtual_run['START_ADAS_ELEVATION_MILLI_METER'].iloc[i]\n",
    "    Data_virtual_run['SLOPE_ANGLE_THETA'].iloc[i] = np.arctan(delta_ELEVATION/(distance_between_segments*1000))\n",
    "    Data_virtual_run['COS_THETA'].iloc[i] = math.cos(Data_virtual_run['SLOPE_ANGLE_THETA'].iloc[i])\n",
    "    Data_virtual_run['SIN_THETA'].iloc[i] = math.sin(Data_virtual_run['SLOPE_ANGLE_THETA'].iloc[i])\n",
    "    if str(Data_virtual_run.iloc[i]['IS_ADAS_NULL'])== 'nan':\n",
    "        Data_virtual_run['IS_ADAS_NULL'].iloc[i] = 0\n",
    "Data_virtual_run['IS_ADAS_NULL'] = Data_virtual_run['IS_ADAS_NULL'].astype('int')\n",
    "\n",
    "print('Virtual constant velocity runing LOG生成完了')\n",
    "print('--------------------------------')\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "########################\n",
    "#get datas of Car on input car_id from SQL server    \n",
    "print('--------------------------------')\n",
    "print('car_idを指定してください(virtual_LEAF2020 is 27,nothing on the car)')\n",
    "car_id = input()\n",
    "car_id = int(car_id)\n",
    "print('車に乗る人や道具の重さの合計を入力してください（kg）')\n",
    "other_wight = input()\n",
    "other_wight = int(other_wight)\n",
    "print('--------------------------------')\n",
    "datas_from_SQL_server_CARS = get_Car_model_datas(car_id)\n",
    "\n",
    "df_Car = pd.DataFrame({},columns = ['CAR_ID',\n",
    "                                    'MODEL',\n",
    "                                    'BATTERY',\n",
    "                                    'WEIGHT',\n",
    "                                    'TIRE_RADIUS',\n",
    "                                    'REDUCTION_RATIO',\n",
    "                                    'CD_VAULE',\n",
    "                                    'FRONTAL_PROJECTED_AREA'])\n",
    "\n",
    "df_Car.loc[0] = list(datas_from_SQL_server_CARS[0])\n",
    "df_Car.WEIGHT.loc[0] = df_Car.WEIGHT.loc[0] + other_wight\n",
    "\n",
    "########################\n",
    "#calculate Ecolog datas base on segment datas and car data \n",
    "print('--------------------------------')\n",
    "print('VCVR LOGによりECOLOG出力を計算しているฅ^•ω•^ฅ,it will take about 30s~60s,maybe more')\n",
    "df_ecolog_calculate = pd.DataFrame({'SEGMENT_ID':[],\n",
    "                                    'LATITUDE':[],\n",
    "                                    'LONGITUDE':[],\n",
    "                                    'ELEVATION_MILLI_METER':[],\n",
    "                                    'SLOPE_ANGLE_THETA':[],\n",
    "                                    'COS_THETA':[],\n",
    "                                    'SIN_THETA':[],\n",
    "                                    'Is_Adas':[]})\n",
    "df_ecolog_calculate.SEGMENT_ID = Data_virtual_run.SEGMENT_ID\n",
    "df_ecolog_calculate.LATITUDE = Data_virtual_run.START_LATITUDE\n",
    "df_ecolog_calculate.LONGITUDE = Data_virtual_run.START_LONGITUDE\n",
    "df_ecolog_calculate.ELEVATION_MILLI_METER = Data_virtual_run.START_ADAS_ELEVATION_MILLI_METER\n",
    "\n",
    "# df_ecolog_calculate.SLOPE_ANGLE_THETA = df_segment_in_semantic.SLOPE_ANGLE_THETA\n",
    "# df_ecolog_calculate.COS_THETA = df_segment_in_semantic.COS_THETA\n",
    "# df_ecolog_calculate.SIN_THETA = df_segment_in_semantic.SIN_THETA\n",
    "df_ecolog_calculate.Is_Adas = 1   # 1 means True\n",
    "df_ecolog_calculate['Speed'] = Speed * 3.6\n",
    "df_ecolog_calculate['Torque'] = 0.0\n",
    "df_ecolog_calculate['EnergyByAirResistance'] = 0.0\n",
    "df_ecolog_calculate['EnergyByRollingResistance'] = 0.0\n",
    "df_ecolog_calculate['EnergyByClimbingResistance'] = 0.0\n",
    "df_ecolog_calculate['EnergyByAccResistance'] = 0.0\n",
    "df_ecolog_calculate['DrivingResistancePower'] = 0.0\n",
    "df_ecolog_calculate['ConvertLoss'] = 0.0\n",
    "df_ecolog_calculate['RegeneLoss'] = 0.0\n",
    "df_ecolog_calculate['RegeneEnergy'] = 0.0\n",
    "df_ecolog_calculate['LostEnergy'] = 0.0\n",
    "df_ecolog_calculate['Efficiency'] = 79\n",
    "df_ecolog_calculate['ConsumedEnergy'] = 0.0\n",
    "\n",
    "for i in range(len(df_ecolog_calculate)):\n",
    "    if i > 0:\n",
    "        delta_ELEVATION = df_ecolog_calculate.ELEVATION_MILLI_METER.iloc[i] - df_ecolog_calculate.ELEVATION_MILLI_METER.iloc[i-1]\n",
    "        df_ecolog_calculate.SLOPE_ANGLE_THETA.iloc[i] = np.arctan(delta_ELEVATION/(segment_distance*1000))\n",
    "        df_ecolog_calculate.COS_THETA.iloc[i] =  math.cos(df_ecolog_calculate.SLOPE_ANGLE_THETA.iloc[i])\n",
    "        df_ecolog_calculate.SIN_THETA.iloc[i] =  math.sin(df_ecolog_calculate.SLOPE_ANGLE_THETA.iloc[i])\n",
    "        \n",
    "        airResistancePower = rho * df_Car['CD_VAULE'].iloc[0] * df_Car['FRONTAL_PROJECTED_AREA'].iloc[0] * Speed * Speed / 2 * Speed / 3600 /1000\n",
    "        rollingResistancePower = myu * df_Car['WEIGHT'].iloc[0] * GravityResistanceCoefficient * df_ecolog_calculate.COS_THETA.iloc[i] * Speed / 3600 /1000\n",
    "        climbingResistancePower = df_Car['WEIGHT'].iloc[0] * GravityResistanceCoefficient * df_ecolog_calculate.SIN_THETA.iloc[i] * Speed / 3600 /1000\n",
    "        drivingResistancePower = airResistancePower+rollingResistancePower+climbingResistancePower+0\n",
    "        df_ecolog_calculate.EnergyByAirResistance.iloc[i] = airResistancePower\n",
    "        df_ecolog_calculate.EnergyByRollingResistance.iloc[i] = rollingResistancePower\n",
    "        df_ecolog_calculate.EnergyByClimbingResistance.iloc[i] = climbingResistancePower\n",
    "        df_ecolog_calculate.EnergyByAccResistance.iloc[i] = 0 #仮想走行では定速なので、加速抵抗がない\n",
    "        df_ecolog_calculate.DrivingResistancePower.iloc[i] = drivingResistancePower\n",
    "        torque = 0 \n",
    "        if Speed > 0:\n",
    "            torque = int(drivingResistancePower * 1000 * 3600 / df_ecolog_calculate.Speed.iloc[i] * df_Car['TIRE_RADIUS'].iloc[0] / df_Car['REDUCTION_RATIO'].iloc[0])\n",
    "            df_ecolog_calculate.Torque.iloc[i] = torque\n",
    "        efficiency = get_efficiency(Speed, torque, df_Car)\n",
    "        df_ecolog_calculate.Efficiency.iloc[i] = efficiency\n",
    "        if drivingResistancePower >= 0:\n",
    "            regeneEnergy = 0\n",
    "            consumedEnergy = drivingResistancePower / efficiency * 100 / InverterEfficiency\n",
    "        else:\n",
    "            regeneEnergy = Calc_RegeneEnergy(drivingResistancePower, Speed, efficiency, df_Car['WEIGHT'].iloc[0])\n",
    "            consumedEnergy = regeneEnergy\n",
    "        df_ecolog_calculate.ConsumedEnergy.iloc[i] = consumedEnergy\n",
    "        df_ecolog_calculate.RegeneEnergy.iloc[i] = regeneEnergy\n",
    "        if drivingResistancePower >= 0:\n",
    "            convertLoss = consumedEnergy * (1 - (1 * efficiency / 100 * InverterEfficiency))\n",
    "            regeneLoss = 0\n",
    "        else:\n",
    "            convertLoss = consumedEnergy * ((1 / efficiency * 100 / InverterEfficiency) - 1)\n",
    "            regeneLoss = drivingResistancePower - regeneEnergy / efficiency * 100 / InverterEfficiency  # こここれで合ってるの？\n",
    "            #regeneLoss = (drivingResistancePower - regeneEnergy) / efficiency * 100 / InverterEfficiency\n",
    "            #if regeneLoss > 0:\n",
    "            #    print(drivingResistancePower, '  ', regeneEnergy, '  ', abs(convertLoss) - regeneLoss)\n",
    "        lostEnergy = abs(convertLoss) - regeneLoss + airResistancePower + rollingResistancePower\n",
    "        df_ecolog_calculate.LostEnergy.iloc[i] = lostEnergy\n",
    "        df_ecolog_calculate.ConvertLoss.iloc[i] = convertLoss\n",
    "        df_ecolog_calculate.RegeneLoss.iloc[i] = regeneLoss\n",
    "print('calculation is done,now outputing the mapping image')\n",
    "print('--------------------------------')\n",
    "\n",
    "\n",
    "print('now outputing the pure version of ecolog-calculation-result to a csv file in \\CSV_ECOLOGtable\\pure_version')\n",
    "output_path_ecolog = Path(rf\"{os.getcwd()}\\CSV_ECOLOGtable\\virtual_run_{semantic_link_id}_acc_setting_speed{Speed_for_output}.csv\")\n",
    "df_ecolog_calculate.to_csv(output_path_ecolog)\n",
    "print('--------------------------------')\n",
    "\n",
    "review_path = Path(rf\"{os.getcwd()}\\FoliumMap\\Only_semantics\\{semantic_link_id}_acc_setting_speed{Speed_for_output}_{segment_distance}m.html\")\n",
    "display_folium_map_from_csv(df_ecolog_calculate,review_path)\n",
    "\n",
    "output_path_Energy_map = Path(rf\"{os.getcwd()}\\xlsx_ECOLOG_EnergyMap\\virtual_run_{semantic_link_id}_acc_setting_speed{Speed_for_output}.xlsx\")\n",
    "df_ecolog_Energy_map = df_ecolog_calculate[['LATITUDE','LONGITUDE','ConsumedEnergy']]\n",
    "df_ecolog_Energy_map.to_excel(output_path_Energy_map)\n",
    "\n",
    "\n",
    "print('all process are done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad068b3",
   "metadata": {},
   "source": [
    "# Credit\n",
    "- ShichiryにkmlとJsonを処理する関数の部分のcodeと、ECOLOG計算式について、教えていただきました\n",
    "- 何新に欠損を埋める部分に協力していただきました\n",
    "- Sogaにエネルギーマップについて親切かつ詳しく解説していただきました、ECOLOG計算式について一緒に議論して再作成しました\n",
    "- prof.Tommyにsegmentと欠損について大変有用な助言をいただきました"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
